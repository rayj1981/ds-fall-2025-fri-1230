{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f93b7be6",
   "metadata": {},
   "source": [
    "\n",
    "# Superstore Business Analytics — CEO/PM Q&A Notebook (All-in-One)\n",
    "\n",
    "This notebook is designed to **teach by doing**: every section starts with a real **business question**, lays out a **statistical plan**, runs the **code**, and then **interprets the result in plain business language**.\n",
    "\n",
    "**Topics covered**\n",
    "- Why Stats Matter in Business\n",
    "- Descriptive Statistics\n",
    "- Probability & Distributions\n",
    "- Sampling & Estimation\n",
    "- Hypothesis Testing\n",
    "- Correlation & Simple OLS\n",
    "- **Time Series** (trend, seasonality, growth, simple forecast)\n",
    "- Extras: ABC/Pareto for products, outliers & risk tails\n",
    "\n",
    "> **How to use**: Set `CSV_PATH` below to your Superstore CSV and run section-by-section in class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4984570",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== Setup & Imports ====\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: f'{x:,.3f}')\n",
    "\n",
    "# EDIT ME: point to your CSV\n",
    "CSV_PATH = 'path/to/your/superstore.csv'  # <-- CHANGE THIS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05850b4d",
   "metadata": {},
   "source": [
    "\n",
    "## Data Loading & Feature Engineering\n",
    "\n",
    "We clean columns, parse dates, coerce numerics, and add teaching-friendly features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ce3204",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EXPECTED_COLS = [\n",
    "    \"Row ID\",\"Order ID\",\"Order Date\",\"Ship Date\",\"Ship Mode\",\"Customer ID\",\n",
    "    \"Customer Name\",\"Segment\",\"Country\",\"City\",\"State\",\"Postal Code\",\"Region\",\n",
    "    \"Product ID\",\"Category\",\"Sub-Category\",\"Product Name\",\"Sales\",\"Quantity\",\n",
    "    \"Discount\",\"Profit\"\n",
    "]\n",
    "\n",
    "def standardize_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.columns = (\n",
    "        df.columns.str.strip().str.lower()\n",
    "        .str.replace(r'[^0-9a-zA-Z]+', '_', regex=True)\n",
    "        .str.strip('_')\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def parse_dates(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    for col in [\"order_date\",\"ship_date\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col], errors=\"coerce\", infer_datetime_format=True)\n",
    "    return df\n",
    "\n",
    "def coerce_types(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    for col in [\"sales\",\"discount\",\"profit\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    if \"quantity\" in df.columns:\n",
    "        df[\"quantity\"] = pd.to_numeric(df[\"quantity\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    return df\n",
    "\n",
    "def add_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    if \"order_date\" in df.columns and df[\"order_date\"].notna().any():\n",
    "        df[\"order_year\"]  = df[\"order_date\"].dt.year\n",
    "        df[\"order_month\"] = df[\"order_date\"].dt.month\n",
    "        df[\"order_ym\"]    = df[\"order_date\"].dt.to_period(\"M\").dt.to_timestamp()\n",
    "    if {\"sales\",\"profit\"}.issubset(df.columns):\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            df[\"margin_rate\"] = np.where(df[\"sales\"]!=0, df[\"profit\"]/df[\"sales\"], np.nan)\n",
    "    if \"discount\" in df.columns:\n",
    "        df[\"discount_bin\"] = pd.cut(df[\"discount\"].fillna(0.0),\n",
    "                                    bins=[-0.01,0.0,0.2,0.4,1.0],\n",
    "                                    labels=[\"0\",\"(0,0.2]\",\"(0.2,0.4]\",\"(0.4,1]\"])\n",
    "    return df\n",
    "\n",
    "def load_superstore(csv_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    keep = [c for c in EXPECTED_COLS if c in df.columns]\n",
    "    df = df[keep]\n",
    "    df = standardize_columns(df)\n",
    "    df = parse_dates(df)\n",
    "    df = coerce_types(df)\n",
    "    df = add_features(df)\n",
    "    return df\n",
    "\n",
    "df = load_superstore(CSV_PATH)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cdb19d",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Descriptive Statistics\n",
    "\n",
    "**Business Question (PM):** *“Where are we making and losing money — by segment, region, and category?”*  \n",
    "**Statistical Plan:** Summarize numeric variables; group KPIs by business dimensions; find top/bottom products.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a50f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def numeric_summary(df, cols=(\"sales\",\"profit\",\"discount\",\"quantity\",\"margin_rate\")):\n",
    "    present = [c for c in cols if c in df.columns]\n",
    "    return df[present].describe(percentiles=[0.25,0.5,0.75]).T\n",
    "\n",
    "def segment_kpis(df):\n",
    "    keys = [c for c in [\"segment\",\"region\",\"category\"] if c in df.columns]\n",
    "    num_cols = [c for c in [\"sales\",\"profit\",\"quantity\",\"discount\",\"margin_rate\"] if c in df.columns]\n",
    "    out = df.groupby(keys)[num_cols].agg([\"count\",\"sum\",\"mean\",\"median\"])\n",
    "    out.columns = [\"_\".join(col).strip(\"_\") for col in out.columns.to_flat_index()]\n",
    "    return out.sort_values(out.columns[0], ascending=False)\n",
    "\n",
    "def top_n_products(df, n=10, by=\"profit\"):\n",
    "    cols = [c for c in [\"product_id\",\"product_name\",\"category\",\"sub_category\",\"sales\",\"profit\"] if c in df.columns]\n",
    "    agg = df[cols].groupby([\"product_id\",\"product_name\",\"category\",\"sub_category\"], dropna=False)[[\"sales\",\"profit\"]].sum()\n",
    "    return agg.sort_values(by=by, ascending=False).head(n).reset_index()\n",
    "\n",
    "summ = numeric_summary(df).round(3)\n",
    "kpis = segment_kpis(df).round(3)\n",
    "tops = top_n_products(df, n=10, by=\"profit\").round(2)\n",
    "\n",
    "display(summ)\n",
    "display(kpis.head(10))\n",
    "display(tops)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708025ce",
   "metadata": {},
   "source": [
    "\n",
    "### Interpretation (tell the story)\n",
    "- **Overall scale & spread:** Use medians/IQR to avoid outlier bias; note if `profit` has heavy tails.  \n",
    "- **Segment/Region/Category:** Identify the **best** (highest median/sum profit) and **worst** performers.  \n",
    "- **Top products:** Are profits concentrated in a few SKUs? That suggests **Pareto/ABC** focus.\n",
    "\n",
    "> **Decision hint:** Double down on high-margin segments/categories; investigate chronic loss-makers for repricing or delisting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0f81b9",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Probability & Distributions\n",
    "\n",
    "**Business Question (CEO):** *“What’s the chance we lose money at different discount levels?”*  \n",
    "**Statistical Plan:** Estimate empirical `P(Profit > 0)` by `discount_bin`; optionally use normal-approx on sales for intuition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5c330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def empirical_probability_profit_positive_by_discount(df):\n",
    "    if not {\"discount_bin\",\"profit\"}.issubset(df.columns):\n",
    "        return pd.DataFrame()\n",
    "    tmp = df.assign(profit_pos=df[\"profit\"] > 0)\n",
    "    return tmp.groupby(\"discount_bin\")[\"profit_pos\"].mean().to_frame(\"p_profit>0\")\n",
    "\n",
    "def normal_approx_prob(series: pd.Series, threshold: float, side: str=\"above\"):\n",
    "    s = series.dropna()\n",
    "    if len(s) < 2: return np.nan\n",
    "    mu, sd = s.mean(), s.std(ddof=1)\n",
    "    if sd <= 0: return float(threshold >= mu) if side==\"above\" else float(threshold <= mu)\n",
    "    z = (threshold - mu) / sd\n",
    "    if side == \"above\": return 1 - stats.norm.cdf(z)\n",
    "    if side == \"below\": return stats.norm.cdf(z)\n",
    "    return 2*(1 - stats.norm.cdf(abs(z)))\n",
    "\n",
    "p_by_disc = empirical_probability_profit_positive_by_discount(df).round(3)\n",
    "display(p_by_disc)\n",
    "\n",
    "if \"sales\" in df.columns:\n",
    "    med = df[\"sales\"].dropna().median()\n",
    "    approx = normal_approx_prob(df[\"sales\"], med, side=\"above\")\n",
    "    print(f\"Normal approx: P(Sales > median) ≈ {approx:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f20f478",
   "metadata": {},
   "source": [
    "\n",
    "### Interpretation\n",
    "- As discount increases, if `P(Profit>0)` **falls**, deep discounts are **riskier**.  \n",
    "- Use as a **risk dial**: which discount bands keep us safely profitable?  \n",
    "- The normal-approx demo is just intuition; rely on empirical results for decisions.\n",
    "\n",
    "> **Decision hint:** Set discount policies where `P(Profit>0)` stays acceptably high; require approvals for deeper cuts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5815bc9",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Sampling & Estimation\n",
    "\n",
    "**Business Question (Analyst):** *“Can we estimate mean profit precisely with a small sample?”*  \n",
    "**Statistical Plan:** Draw a simple random sample; compute a bootstrap **95% CI** for mean profit; calculate sample size for a desired MOE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f28296b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Tuple\n",
    "\n",
    "def take_sample(df, n=500, random_state=42):\n",
    "    n = min(n, len(df))\n",
    "    return df.sample(n=n, random_state=random_state)\n",
    "\n",
    "def bootstrap_mean_ci(series: pd.Series, n_boot: int = 2000, alpha: float = 0.05, random_state: int = 42) -> Tuple[float,float,float]:\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    s = series.dropna().values\n",
    "    if len(s) == 0: return (np.nan, np.nan, np.nan)\n",
    "    boot = []\n",
    "    for _ in range(n_boot):\n",
    "        sample = rng.choice(s, size=len(s), replace=True)\n",
    "        boot.append(sample.mean())\n",
    "    lo, hi = np.percentile(boot, [100*alpha/2, 100*(1-alpha/2)])\n",
    "    return (float(np.mean(s)), float(lo), float(hi))\n",
    "\n",
    "def sample_size_mean(sd: float, margin_error: float, z: float = 1.96) -> int:\n",
    "    if margin_error <= 0 or sd <= 0: return np.nan\n",
    "    return int(np.ceil((z*sd / margin_error)**2))\n",
    "\n",
    "sample = take_sample(df, n=500)\n",
    "mean_profit, lo, hi = bootstrap_mean_ci(sample[\"profit\"])\n",
    "sd_profit = df[\"profit\"].std()\n",
    "n_needed = sample_size_mean(sd=sd_profit, margin_error=5.0)\n",
    "\n",
    "print(f\"Bootstrap 95% CI for mean Profit (n={len(sample)}): mean={mean_profit:,.2f}, CI=({lo:,.2f}, {hi:,.2f})\")\n",
    "print(f\"Required n for ±$5 MOE (~95%): {n_needed}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0db7e2",
   "metadata": {},
   "source": [
    "\n",
    "### Interpretation\n",
    "- The **CI** tells us the plausible range for mean profit; if it’s narrow enough, the estimate is **decision-grade**.  \n",
    "- The **sample-size** figure helps plan data collection or experiment scale.\n",
    "\n",
    "> **Decision hint:** If leadership needs ±$5 precision, ensure samples meet or exceed the computed `n`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f53200",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Hypothesis Testing\n",
    "\n",
    "**Business Question (CEO):** *“Do deep discounts (>20%) **reduce** average profit?”*  \n",
    "**Statistical Plan:** Two-sample **t-test** comparing mean profit between `discount <= 0.2` and `> 0.2`. Also test **segments** (two-proportion z), **regions** (ANOVA), and **Category×Region** (chi-square).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e440e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ttest_profit_by_discount(df, split=0.2):\n",
    "    low  = df.loc[df[\"discount\"] <= split, \"profit\"].dropna()\n",
    "    high = df.loc[df[\"discount\"] >  split, \"profit\"].dropna()\n",
    "    res = stats.ttest_ind(low, high, equal_var=False)\n",
    "    return {\n",
    "        \"n_low\": int(low.shape[0]), \"n_high\": int(high.shape[0]),\n",
    "        \"mean_low\": float(low.mean() if len(low)>0 else np.nan),\n",
    "        \"mean_high\": float(high.mean() if len(high)>0 else np.nan),\n",
    "        \"t_stat\": float(res.statistic), \"p_value\": float(res.pvalue)\n",
    "    }\n",
    "\n",
    "def prop_test_profit_positive_by_segment(df):\n",
    "    tmp = df.assign(pos=df[\"profit\"]>0)\n",
    "    counts = tmp.groupby(\"segment\")[\"pos\"].agg([\"sum\",\"count\"]).sort_values(\"count\", ascending=False)\n",
    "    if counts.shape[0] < 2: return None\n",
    "    (x1,n1),(x2,n2) = counts.iloc[0].tolist(), counts.iloc[1].tolist()\n",
    "    p1,p2 = x1/n1, x2/n2\n",
    "    p_pool = (x1+x2)/(n1+n2)\n",
    "    se = (p_pool*(1-p_pool)*(1/n1 + 1/n2))**0.5\n",
    "    z  = (p1 - p2) / se if se>0 else np.nan\n",
    "    p  = 2*(1 - stats.norm.cdf(abs(z))) if np.isfinite(z) else np.nan\n",
    "    return {\"segments\": counts.index[:2].tolist(), \"p1\": float(p1), \"p2\": float(p2), \"z\": float(z), \"p_value\": float(p)}\n",
    "\n",
    "def anova_profit_by_region(df):\n",
    "    groups = [g[\"profit\"].dropna().values for _, g in df.groupby(\"region\")]\n",
    "    if len(groups) < 2: return None\n",
    "    f, p = stats.f_oneway(*groups)\n",
    "    return {\"k_groups\": len(groups), \"F\": float(f), \"p_value\": float(p)}\n",
    "\n",
    "def chi_square_category_region(df):\n",
    "    tab = pd.crosstab(df[\"category\"], df[\"region\"])\n",
    "    chi2 = stats.chi2_contingency(tab)\n",
    "    return {\"chi2\": float(chi2[0]), \"p_value\": float(chi2[1]), \"dof\": int(chi2[2]), \"expected_shape\": tab.shape}\n",
    "\n",
    "res_t = ttest_profit_by_discount(df)\n",
    "res_p = prop_test_profit_positive_by_segment(df)\n",
    "res_a = anova_profit_by_region(df)\n",
    "res_c = chi_square_category_region(df)\n",
    "\n",
    "display(res_t)\n",
    "display(res_p)\n",
    "display(res_a)\n",
    "display(res_c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb354bd1",
   "metadata": {},
   "source": [
    "\n",
    "### Interpretation\n",
    "- **T-test (discounts):** If `mean_high << mean_low` and `p_value < 0.05`, deep discounts are **statistically associated** with lower profits.  \n",
    "- **Proportions (segments):** Significant `p_value` implies **profitability rate** differs between top segments → tailor strategies.  \n",
    "- **ANOVA (regions):** Significant result → at least one region’s mean profit differs → investigate drivers (shipping, pricing, mix).  \n",
    "- **Chi-square (Category×Region):** Significant → sales mix varies by region → regional assortment or marketing.\n",
    "\n",
    "> **Decision hint:** Tighten discount controls; run targeted experiments by segment/region to confirm causality before policy changes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd6be4a",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Correlation & Simple OLS\n",
    "\n",
    "**Business Question (CFO):** *“How do discount, quantity, and sales **relate** to profit? Can we get a quick predictive read?”*  \n",
    "**Statistical Plan:** Compute Pearson & Spearman correlations; fit a compact OLS model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d2e2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pearson_spearman(df, x=\"discount\", y=\"profit\"):\n",
    "    s = df[[x,y]].dropna()\n",
    "    if len(s) < 3: return None\n",
    "    r_pear, p_pear = stats.pearsonr(s[x], s[y])\n",
    "    r_spear, p_spear = stats.spearmanr(s[x], s[y])\n",
    "    return {\"pearson_r\": float(r_pear), \"pearson_p\": float(p_pear),\n",
    "            \"spearman_rho\": float(r_spear), \"spearman_p\": float(p_spear), \"n\": int(len(s))}\n",
    "\n",
    "def simple_ols(df, y=\"profit\", X=(\"discount\",\"quantity\",\"sales\")):\n",
    "    cols = [c for c in X if c in df.columns]\n",
    "    dat = df[[y] + cols].dropna()\n",
    "    if dat.shape[0] < len(cols) + 3: return None\n",
    "    Xmat = sm.add_constant(dat[cols])\n",
    "    model = sm.OLS(dat[y], Xmat).fit()\n",
    "    return {\"nobs\": int(model.nobs), \"r2\": float(model.rsquared),\n",
    "            \"coef\": {k: float(v) for k, v in model.params.to_dict().items()},\n",
    "            \"pvalues\": {k: float(v) for k, v in model.pvalues.to_dict().items()}}\n",
    "\n",
    "corrs = pearson_spearman(df, x=\"discount\", y=\"profit\")\n",
    "ols   = simple_ols(df, y=\"profit\", X=(\"discount\",\"quantity\",\"sales\"))\n",
    "\n",
    "display(corrs)\n",
    "display(ols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ca737b",
   "metadata": {},
   "source": [
    "\n",
    "### Interpretation\n",
    "- **Correlation:** Sign and magnitude tell us direction/strength (watch for nonlinearity & confounders).  \n",
    "- **OLS:** Coefficients show marginal associations holding other included variables constant. Use for **directional insight**, not causation.\n",
    "\n",
    "> **Decision hint:** If discount coefficient is strongly negative and significant, prioritize pricing experiments; if quantity/sales coefficients are positive, consider volume-driving tactics (with margin guardrails).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c265418b",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Time Series (Trend, Seasonality, Growth, Simple Forecast)\n",
    "\n",
    "**Business Question (CEO):** *“How are sales and profit trending over time? What do we expect next month?”*  \n",
    "**Statistical Plan:** Aggregate by month; compute moving averages and YoY growth; decompose seasonality; produce a simple naive/MA forecast.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664cba37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Monthly aggregates\n",
    "ts = df.dropna(subset=[\"order_ym\"]).groupby(\"order_ym\")[[\"sales\",\"profit\"]].sum().sort_index()\n",
    "\n",
    "# 3-month moving averages\n",
    "ts[\"sales_ma3\"]  = ts[\"sales\"].rolling(3, min_periods=1).mean()\n",
    "ts[\"profit_ma3\"] = ts[\"profit\"].rolling(3, min_periods=1).mean()\n",
    "\n",
    "# YoY growth if ≥ 12 months\n",
    "if len(ts) >= 13:\n",
    "    ts[\"sales_yoy\"]  = ts[\"sales\"].pct_change(12)\n",
    "    ts[\"profit_yoy\"] = ts[\"profit\"].pct_change(12)\n",
    "\n",
    "display(ts.tail(12))\n",
    "\n",
    "# Seasonal decomposition (additive) if enough points\n",
    "decomp_summary = {}\n",
    "if len(ts) >= 24:\n",
    "    decomp = seasonal_decompose(ts[\"sales\"], model=\"additive\", period=12, two_sided=False, extrapolate_trend='freq')\n",
    "    decomp_summary = {\n",
    "        \"trend_last\": float(decomp.trend.dropna().iloc[-1]) if decomp.trend is not None else np.nan,\n",
    "        \"seasonal_peek\": float(decomp.seasonal.groupby(ts.index.month).mean().max()),\n",
    "        \"seasonal_trough\": float(decomp.seasonal.groupby(ts.index.month).mean().min()),\n",
    "    }\n",
    "decomp_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b28a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simple forecasts: last-value (naive) and MA(3) extrapolation\n",
    "def naive_forecast(series: pd.Series):\n",
    "    return float(series.dropna().iloc[-1]) if len(series.dropna()) else np.nan\n",
    "\n",
    "def ma3_forecast(series: pd.Series):\n",
    "    s = series.dropna()\n",
    "    if len(s) == 0: return np.nan\n",
    "    return float(s.rolling(3, min_periods=1).mean().iloc[-1])\n",
    "\n",
    "next_sales_naive = naive_forecast(ts[\"sales\"])\n",
    "next_sales_ma3   = ma3_forecast(ts[\"sales\"])\n",
    "next_profit_naive = naive_forecast(ts[\"profit\"])\n",
    "next_profit_ma3   = ma3_forecast(ts[\"profit\"])\n",
    "\n",
    "print(f\"Next-month Sales (naive): {next_sales_naive:,.0f} | MA(3): {next_sales_ma3:,.0f}\")\n",
    "print(f\"Next-month Profit (naive): {next_profit_naive:,.0f} | MA(3): {next_profit_ma3:,.0f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a56a5e5",
   "metadata": {},
   "source": [
    "\n",
    "### Interpretation\n",
    "- **Trend:** Use MA(3) and decomposition trend to describe direction (up/down/flat).  \n",
    "- **Seasonality:** Peaks/troughs reveal planning windows (inventory, promos).  \n",
    "- **Growth:** YoY increasing? That supports expansion decisions.  \n",
    "- **Forecast:** Naive/MA give a **baseline**; refine with ARIMA/Prophet if needed.\n",
    "\n",
    "> **Decision hint:** Align promotions to seasonal peaks, ensure capacity before expected upswings, and set targets using conservative (naive) vs optimistic (MA) baselines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f6b84e",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Extras — ABC/Pareto, Outliers & Risk Tails\n",
    "\n",
    "**Business Question (Merchandising):** *“Which SKUs drive most of our profit, and where are extreme losses coming from?”*  \n",
    "**Statistical Plan:** Pareto rank by cumulative profit (ABC); inspect tail losses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4289f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pareto on product profit\n",
    "prod = df.groupby([\"product_id\",\"product_name\"], dropna=False)[\"profit\"].sum().sort_values(ascending=False).reset_index()\n",
    "prod[\"cum_profit\"] = prod[\"profit\"].cumsum()\n",
    "total_profit = prod[\"profit\"].sum()\n",
    "prod[\"cum_share\"] = prod[\"cum_profit\"] / total_profit if total_profit != 0 else np.nan\n",
    "\n",
    "def abc_class(share):\n",
    "    if pd.isna(share): return np.nan\n",
    "    if share <= 0.80: return \"A\"\n",
    "    if share <= 0.95: return \"B\"\n",
    "    return \"C\"\n",
    "\n",
    "prod[\"ABC\"] = prod[\"cum_share\"].apply(abc_class)\n",
    "display(prod.head(15))\n",
    "\n",
    "# Loss tail: worst 1% of line items by profit\n",
    "cut = np.nanpercentile(df[\"profit\"], 1)\n",
    "tail_losses = df.loc[df[\"profit\"] <= cut, [\"order_id\",\"product_name\",\"category\",\"sub_category\",\"discount\",\"profit\"]].sort_values(\"profit\").head(20)\n",
    "display(tail_losses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136ea1de",
   "metadata": {},
   "source": [
    "\n",
    "### Interpretation\n",
    "- **ABC:** A small fraction of SKUs likely drives most profit (A items). Protect availability and margins there.  \n",
    "- **Loss tail:** Identify patterns (e.g., deep discounts, certain categories) and set **guardrails**.\n",
    "\n",
    "> **Decision hint:** Prioritize A-items for inventory/assortment; review pricing/discounts for chronic loss-makers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e4c6aa",
   "metadata": {},
   "source": [
    "\n",
    "## Wrap-Up & Recommendations\n",
    "\n",
    "- **Descriptives** surfaced where we win/lose.  \n",
    "- **Probability** quantified risk by discount.  \n",
    "- **Sampling/CI** gave precision planning.  \n",
    "- **Hypothesis tests** backed policy choices with evidence.  \n",
    "- **Correlation/OLS** offered directional drivers.  \n",
    "- **Time series** informed planning and simple forecasting.  \n",
    "- **Pareto/Outliers** focused attention where it matters most.\n",
    "\n",
    "**Next steps for the team**\n",
    "1. Define discount guardrails based on `P(Profit>0)` and t-test outcomes.  \n",
    "2. Pilot **segment/region-targeted** strategies to validate causality.  \n",
    "3. Use the MA/naive forecasts to set next-month targets; refine with ARIMA later.  \n",
    "4. Maintain an **A/B test calendar** to turn insights into controlled experiments.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
